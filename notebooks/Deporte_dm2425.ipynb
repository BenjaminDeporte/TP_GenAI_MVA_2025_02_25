{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master MVA- Generative Modeling\n",
    "### Assignment 25th Feb\n",
    "### Benjamin Deporte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "# If you don't want to bother with the device, stay on cpu:\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "# set seeds for reproductibility\n",
    "random_seed = 42\n",
    "rng = np.random.default_rng(seed=random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soyons fous... nous utiliserons 2-moons ici\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# paramètres\n",
    "N_SAMPLES = 200\n",
    "NOISE = 0.05\n",
    "\n",
    "# génération données\n",
    "X, _ = make_moons(n_samples=N_SAMPLES, noise=NOISE, random_state=random_seed)\n",
    "\n",
    "# force dans [0,1]^2\n",
    "# X[:,0] = (X[:,0] - np.min(X[:,0])) / (np.max(X[:,0]) - np.min(X[:,0]))\n",
    "# X[:,1] = (X[:,1] - np.min(X[:,1])) / (np.max(X[:,1]) - np.min(X[:,1]))\n",
    "\n",
    "# formate en tensor\n",
    "X_data = torch.tensor(X).to(device)\n",
    "\n",
    "# plot dataset\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(X_data.detach().cpu().numpy()[:,0], X_data.detach().cpu().numpy()[:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator - on ré-utilise le code du TP\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, n_out, n_hid=10, nlayers=3, device=device):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.n_hid = n_hid\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        # create nlayers of nn.Linear of size\n",
    "        # - n_in for the first one\n",
    "        # - n_hid for the others\n",
    "        for n in range(nlayers):\n",
    "            n_in_t = n_in if n==0 else n_hid\n",
    "            self.hidden.append(nn.Sequential(\n",
    "            nn.Linear(n_in_t, n_hid),\n",
    "            nn.ELU(1)\n",
    "        ).to(device))\n",
    "\n",
    "        # otuput layer, n_out neurons then Sigmoid\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_out),\n",
    "            # nn.Sigmoid()\n",
    "        ).to(device)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for n in range(self.nlayers):\n",
    "            x = self.hidden[n](x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight, 1.0)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 10    # input dimension, dimension de la Gaussienne dont est tiré z\n",
    "d = 2        # dimension des data points\n",
    "\n",
    "b = 100      # batch size\n",
    "\n",
    "# Initialise générateur\n",
    "G = Generator(n_in=n_in, n_out=d, n_hid=100, nlayers=3, device=device)\n",
    "\n",
    "# Draw a batch x of generated points\n",
    "#    Input noise z : standard normal with shape (b, n_in)\n",
    "z = torch.randn(b, n_in, device=device)\n",
    "X_gen = G(z).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(x_data=X_data, x_gen=None):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    ax.scatter(x_gen[:,0], x_gen[:,1], c='deepskyblue')\n",
    "    ax.scatter(x_data[:,0], x_data[:,1], c='navy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste le sampling\n",
    "\n",
    "display(X_data.cpu(), X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator - code TP\n",
    "\n",
    "class DiscriminatorGAN(nn.Module):\n",
    "  def __init__(self, n_in=2, n_hid=10, device=device):\n",
    "    super(DiscriminatorGAN, self).__init__()\n",
    "\n",
    "    # n_in is the input dimension, 2 here as data points are 2D\n",
    "    self.n_hid = n_hid\n",
    "    self.n_in = n_in    \n",
    "\n",
    "    self.fc1 = nn.Linear(n_in, n_hid).to(device)\n",
    "    self.fc2 = nn.Linear(n_hid, n_hid).to(device)\n",
    "    self.fc3 = nn.Linear(n_hid, 1).to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    y = nn.LeakyReLU(negative_slope=0.2)(self.fc1(x))\n",
    "    y = nn.LeakyReLU(negative_slope=0.2)(self.fc2(y))\n",
    "    # proba que x soit issu de p_data et non pas p_gen = G(p_z)\n",
    "    y = nn.Sigmoid()(self.fc3(y))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP code Evolution :\n",
    "- commented code regarding gradient clipping\n",
    "- added kwarg \"GenFreeze\" to allow training of Discriminator only\n",
    "- a couple of prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(\n",
    "  GenFreeze=False,\n",
    "  niterD=100,\n",
    "  niterG=1,\n",
    "  n_epochs=50,\n",
    "  lrdisc=1e-2,\n",
    "  lrgen=1e-3,\n",
    "  iter_display=10\n",
    "  ):\n",
    "  \n",
    "  # Report out\n",
    "  print(f\"Training GAN - GenFreeze={GenFreeze}\")\n",
    "  # Training loop\n",
    "\n",
    "  # parameters\n",
    "  lrgen = lrgen   # learning rate for generator\n",
    "  lrdisc = lrdisc  # learning rate for discriminator\n",
    "  n_epochs = n_epochs\n",
    "  niterD=niterD\n",
    "  niterG=niterG\n",
    "\n",
    "  # Initialize generator and discriminator\n",
    "  G = Generator(n_in=n_in, n_out=d, n_hid=100, nlayers=3, device=device)\n",
    "  D = DiscriminatorGAN(n_in=d, n_hid=100, device=device)\n",
    "\n",
    "  # get ready\n",
    "  optimG = optim.Adam(G.parameters(), lr=lrgen)\n",
    "  optimD = optim.Adam(D.parameters(), lr=lrdisc) #, betas=(beta_1, beta_2))\n",
    "\n",
    "  # logs\n",
    "  Glosses = []\n",
    "  Dlosses = []\n",
    "\n",
    "  # reporting \n",
    "  iter_display = iter_display\n",
    "\n",
    "  # Main loop\n",
    "  for epoch in range(1,n_epochs):\n",
    "\n",
    "      ###########################################\n",
    "      ### Train discriminator (niterD iterations)\n",
    "      ###########################################\n",
    "      \n",
    "      #### ie max sur D de la loss\n",
    "      for iter in range(0,niterD):\n",
    "        optimD.zero_grad()\n",
    "        X_gen = G(torch.randn(b, n_in, device=device))\n",
    "        Dx = D(X_gen)\n",
    "        # we want to maximize D(X_data) and minimize D(X_gen)\n",
    "        # Dloss should be as small as possible\n",
    "        Dloss = - (torch.mean(D(X_data)) - torch.mean(Dx))\n",
    "        optimD.zero_grad()\n",
    "        Dloss.backward()\n",
    "        optimD.step()\n",
    "        # GAN : no gradient cliping !\n",
    "        # for p in D.parameters():\n",
    "        #     p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "      #######################################\n",
    "      ### Train generator (niterG iterations)\n",
    "      #######################################\n",
    "      ### ie min sur G de la loss\n",
    "      for iter in range(0,niterG):\n",
    "        # we want to maximize D(G(z))\n",
    "        # Gloss should be as small as possible\n",
    "        Gloss = - torch.mean(D(G(torch.randn(b, n_in, device=device))))\n",
    "        if GenFreeze is not True:\n",
    "          optimG.zero_grad()\n",
    "          Gloss.backward()\n",
    "          optimG.step()\n",
    "\n",
    "      # Output training stats\n",
    "      print('[%d/%d] \\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "        % (epoch, n_epochs, Dloss.item(), Gloss.item()))\n",
    "      Glosses.append(Gloss.item())\n",
    "      Dlosses.append(Dloss.item())\n",
    "\n",
    "      # draw pictures from time to time\n",
    "      if(epoch % iter_display == 0):\n",
    "          fig, ax = plt.subplots(figsize=(4, 4))\n",
    "          # plot data\n",
    "          ax.scatter(X_data.cpu()[:,0], X_data.cpu()[:,1], c='navy')\n",
    "          # plot generated points\n",
    "          z = torch.randn(b, n_in, device=device)\n",
    "          x_gen = G(z).detach().cpu().numpy()\n",
    "          ax.scatter(x_gen[:,0], x_gen[:,1], c='deepskyblue')\n",
    "          plt.show()\n",
    "\n",
    "  ### Plot the evolution of the discriminator and generator losses ###\n",
    "  plt.figure(dpi=100)\n",
    "  plt.plot(Dlosses,label='D')\n",
    "  plt.plot(Glosses,label='G')\n",
    "  plt.title(f'Loss evolution - GenFreeze={GenFreeze}')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training D, fixed G\n",
    "\n",
    "Ok, we succeed in training D (sort of : -.80 loss vs -1.00 optimal) when G is frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_GAN(GenFreeze=True, lrdisc=1e-3, n_epochs=200, iter_display=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full training of D and G\n",
    "\n",
    "We put 500 training iterations on D for 1 (one !) on G.\n",
    "Still, training fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_GAN(GenFreeze=False, niterD=100, lrdisc=1e-3, n_epochs=100, iter_display=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.a Comment on the differences with respect to the WGAN learning algorithm.\n",
    "\n",
    "The vanilla loss of GANs leads to try to optimise a JS divergence (in fact, two KL-divergences), between $p_{data}$ the probability distribution of the data in $\\mathbb{R}^2$, and $p_{gen}(G(z))$ the probability distribution of $G(z)$ where $G$ is the generator and $z$ is drawn from a Gaussian. Issues arise when the supports of $p_{data}$ and  $p_{gen}(G(z))$ are disjoint, or worse, separated. Then the KLs go to infinity and the gradients vanish, making training unstable.\n",
    "\n",
    "The WGAN loss is a Wasserstein loss, more precisely uses the dual formulation of the Wasserstein distance, based on Lipschitz functions. The Wasserstein distance has better conitnuity and differentiability properties than KL (euphemism) making training, theoretically, easier. However, the training algorithm needs to contain the gradient of the functions to keep them Lipschitz (ie by clipping or by regularization with gradient-penalty)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.b. Comment on the possible stability problems that you may encounter with the GAN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said above, the issue arises when the supports of $p_{data}$ and $p_{gen}(G(z))$ are disjoint, or worse, separated. The gradients vanish, we can get to a mode collapse, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolution of the code\n",
    "\n",
    "- added kwargs clip (Boolean) and grad_penalty (Boolean) to choose Lipschitz enforcement\n",
    "- coded (and added printing) D gradient norm estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_WGAN(\n",
    "  GenFreeze=False,\n",
    "  niterD=100,\n",
    "  niterG=1,\n",
    "  lrdisc=1e-2,\n",
    "  lrgen=1e-3,\n",
    "  iter_display=10,\n",
    "  n_epochs=50,\n",
    "  lambd = 1.0, # regul coeff for gradient penalty\n",
    "  clip_value = 0.05,\n",
    "  clip=False,\n",
    "  grad_penalty=False\n",
    "  ):\n",
    "  \"\"\"WGAN Training - same as GAN, but added regularization\n",
    "  \"\"\"\n",
    "  \n",
    "  # Report out\n",
    "  print(f\"Training WGAN - GenFreeze={GenFreeze}\")\n",
    "  \n",
    "  if clip is False and grad_penalty is False:\n",
    "    print(f\"No regularization\")\n",
    "  elif clip is True:\n",
    "    print(f\"Clipping gradient with clip_value = {clip_value}\")\n",
    "  else:\n",
    "    print(f\"Gradient penalty with lambda = {lambd}\")\n",
    "  \n",
    "  # Training loop\n",
    "\n",
    "  # parameters\n",
    "  lrgen = lrgen   # learning rate for generator\n",
    "  lrdisc = lrdisc  # learning rate for discriminator\n",
    "  n_epochs = n_epochs\n",
    "  niterD=niterD\n",
    "  niterG=niterG\n",
    "  lambd=lambd\n",
    "  clip_value=clip_value\n",
    "\n",
    "  # Initialize generator and discriminator\n",
    "  G = Generator(n_in=n_in, n_out=d, n_hid=100, nlayers=3, device=device)\n",
    "  D = DiscriminatorGAN(n_in=d, n_hid=100, device=device)\n",
    "\n",
    "  # get ready\n",
    "  optimG = optim.Adam(G.parameters(), lr=lrgen)\n",
    "  optimD = optim.Adam(D.parameters(), lr=lrdisc) #, betas=(beta_1, beta_2))\n",
    "\n",
    "  # logs\n",
    "  Glosses = []\n",
    "  Dlosses = []\n",
    "  Gradient_norms = []\n",
    "\n",
    "  # reporting \n",
    "  iter_display = iter_display\n",
    "  \n",
    "  # misc\n",
    "  n_data = X_data.shape[0]\n",
    "\n",
    "  # Main loop\n",
    "  for epoch in range(1,n_epochs):\n",
    "\n",
    "      ###########################################\n",
    "      ### Train discriminator (niterD iterations)\n",
    "      ###########################################\n",
    "      \n",
    "      #### ie max sur D de la loss\n",
    "      for iter in range(0,niterD):\n",
    "        g_norm_ests = []\n",
    "        optimD.zero_grad()\n",
    "        X_gen = G(torch.randn(b, n_in, device=device))\n",
    "        Dx = D(X_gen)\n",
    "        # we want to maximize D(X_data) and minimize D(X_gen)\n",
    "        # Dloss should be as small as possible\n",
    "        Dloss = - (torch.mean(D(X_data)) - torch.mean(Dx))\n",
    "        \n",
    "        if grad_penalty is True and clip is False:\n",
    "          # Estimate Gradient of Discriminator\n",
    "          \n",
    "          # Sample points from the generator\n",
    "          z = torch.randn(n_data, n_in, device=device)\n",
    "          x = G(z) # shape : N x 2\n",
    "          # Calculate interpolation between data and generated points\n",
    "          alpha = torch.rand((n_data,1),device=device) # N x 1\n",
    "          interp = (alpha * n_data + (1-alpha) * x) # .flatten(end_dim=1) # N x 2\n",
    "          interp.requires_grad_()\n",
    "          \n",
    "          D_interp = D(interp) # N x 1\n",
    "          gradout = torch.ones(D_interp.size()).to(device) # N x 1\n",
    "          # autograd will actually compute a Gradient tensor N x 2, as output is N x scalar and input is N x 2\n",
    "          gradients = torch.autograd.grad(outputs = D_interp, inputs = interp, grad_outputs = gradout, create_graph = True, retain_graph = True)[0] # N x 2\n",
    "          \n",
    "          est_gradient_norm = torch.mean(torch.sqrt((torch.sum(gradients**2,dim=1)))) # N x 1\n",
    "          \n",
    "          # print(f\"Gradient norm estimate : {est_gradient_norm}\")\n",
    "          \n",
    "          g_norm_ests.append(est_gradient_norm.item())\n",
    "          # # calculate the loss with gradient penalty\n",
    "          Dloss += lambd * (est_gradient_norm - 1)**2\n",
    "        \n",
    "        # clipping gradients if required\n",
    "        if clip is True and grad_penalty is False:\n",
    "          for p in D.parameters():\n",
    "            p.data.clamp_(-clip_value, clip_value)\n",
    "            \n",
    "        # optimize\n",
    "        optimD.zero_grad()\n",
    "        Dloss.backward()\n",
    "        optimD.step()\n",
    "\n",
    "      if grad_penalty is True and clip is False:\n",
    "        Gradient_norms.append(np.average(g_norm_ests))\n",
    "\n",
    "      #######################################\n",
    "      ### Train generator (niterG iterations)\n",
    "      #######################################\n",
    "      ### ie min sur G de la loss\n",
    "      for iter in range(0,niterG):\n",
    "        # we want to maximize D(G(z))\n",
    "        # Gloss should be as small as possible\n",
    "        Gloss = - torch.mean(D(G(torch.randn(b, n_in, device=device))))\n",
    "        if GenFreeze is not True:\n",
    "          optimG.zero_grad()\n",
    "          Gloss.backward()\n",
    "          optimG.step()\n",
    "\n",
    "      # Output training stats\n",
    "      if grad_penalty is False:\n",
    "        print('[%d/%d] \\tLoss_D: %.4f \\tLoss_G: %.4f'\n",
    "          % (epoch, n_epochs, Dloss.item(), Gloss.item()))\n",
    "      else:\n",
    "        print('[%d/%d] \\tLoss_D: %.4f \\tLoss_G: %.4f \\tGradient_norm_est: %.4f'\n",
    "          % (epoch, n_epochs, Dloss.item(), Gloss.item(), np.average(g_norm_ests)))\n",
    "      Glosses.append(Gloss.item())\n",
    "      Dlosses.append(Dloss.item())\n",
    "\n",
    "      # draw pictures from time to time\n",
    "      if(epoch % iter_display == 0):\n",
    "          fig, ax = plt.subplots(figsize=(4, 4))\n",
    "          # plot data\n",
    "          ax.scatter(X_data.cpu()[:,0], X_data.cpu()[:,1], c='navy')\n",
    "          # plot generated points\n",
    "          z = torch.randn(b, n_in, device=device)\n",
    "          x_gen = G(z).detach().cpu().numpy()\n",
    "          ax.scatter(x_gen[:,0], x_gen[:,1], c='deepskyblue')\n",
    "          plt.show()\n",
    "\n",
    "  ### Plot the evolution of the discriminator and generator losses ###\n",
    "  plt.figure(dpi=100)\n",
    "  plt.plot(Dlosses,label='D')\n",
    "  plt.plot(Glosses,label='G')\n",
    "  # plt.plot(Gradient_norms, label='Gradient Norm Discriminator')\n",
    "  plt.title(f'Loss evolution - GenFreeze={GenFreeze}')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN-WC\n",
    "\n",
    "Testing weight clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, training Discriminator with Generator frozen\n",
    "\n",
    "train_WGAN(GenFreeze=True, lrdisc=1e-3, niterD=100, clip=True, clip_value=10.0, iter_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, training both Discriminator and Generator\n",
    "\n",
    "train_WGAN(GenFreeze=False, niterD=50, lrdisc=1e-3, iter_display=10, clip=True, n_epochs=100, clip_value=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hum. Training failed with that set of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, training Discriminator with Generator frozen\n",
    "\n",
    "train_WGAN(GenFreeze=True, lrdisc=1e-4, niterD=100, grad_penalty=True, n_epochs=50, lambd=1.0, iter_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, trying to train both Discriminator and Generator.\n",
    "\n",
    "train_WGAN(GenFreeze=False, lrdisc=1e-4, niterD=100, lrgen=1e-4, grad_penalty=True, lambd=10.0, n_epochs=50, iter_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still very difficult to train anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We code here a very simple VAE. \n",
    "\n",
    "The Encoder is going to encode from $\\mathbb{R}^2$ into $\\mathbb{R}^d$ (ie dim-d latent space), and decoder from $\\mathbb{R}^d$ to $\\mathbb{R}^2$.\n",
    "\n",
    "The loss is the usual ELBO with a closed-form expression of the KL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_neurons=16, latent_dim=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(2, n_neurons) # input dim = 2\n",
    "        self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc_mu = nn.Linear(n_neurons, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(n_neurons, latent_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x : B x 2\n",
    "        # print(f\"entrée encodeur = {x}\")\n",
    "        x = F.relu(self.fc1(x)) # B x n_neurons\n",
    "        # print(f\"1ere layer encodeur = {x}\")\n",
    "        x = F.relu(self.fc2(x)) # B x n_neurons\n",
    "        # print(f\"2e layer encodeur = {x}\")\n",
    "        mu = self.fc_mu(x) # B x latent_dim : mu's of the Gaussians\n",
    "        # print(f\"sortie mu encodeur = {mu}\")\n",
    "        logvar = self.fc_logvar(x) # B x latent_dim : covariance matrix (assumed diagonal) of the Gaussians\n",
    "        # print(f\"sortie logvar encodeur = {logvar}\")\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_neurons=16, latent_dim=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dim, n_neurons)\n",
    "        self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc3 = nn.Linear(n_neurons, 2)\n",
    "        \n",
    "    def forward(self,z):\n",
    "        # z : B x latent_dim\n",
    "        z = F.relu(self.fc1(z)) # B x n_neurons\n",
    "        z = F.relu(self.fc2(z)) # B x n_neurons\n",
    "        z = self.fc3(z) # B x 2\n",
    "        # print(f\"z_decoder = {z}\")\n",
    "        x_hat = z # B x 2 in [0,1]^2\n",
    "        # print(f\"x_hat = sigmoid(z_decoder) = {x_hat}\")\n",
    "        \n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyVAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_neurons=16, latent_dim=2): #, scale=1.0):\n",
    "        super(ToyVAE, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(n_neurons=n_neurons, latent_dim=latent_dim)\n",
    "        self.decoder = Decoder(n_neurons=n_neurons, latent_dim=latent_dim)\n",
    "        # self.scale = scale\n",
    "        \n",
    "    def rsample(self, mean, std): #, scale=None):\n",
    "        # mean : B x latent_dim\n",
    "        # std : B x latent_dim\n",
    "        # if scale is None:\n",
    "        #     scale=self.scale\n",
    "        epsilon = torch.randn_like(mean) # N(0,1) shape B x latent_dim \n",
    "        z = mean + std * epsilon # * scale # B x 1 \\sim \\mathcal{N}(mu, var)\n",
    "        return z\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        # print(f\"entrée de rsample : mu = {mu}\")\n",
    "        # print(f\"entrée de rsample : std = {std}\")\n",
    "        z = self.rsample(mu, std)\n",
    "        # print(f\"sortie de rsample = {z}\")\n",
    "        # print(f\"z samplé = {z}\")\n",
    "        x_hat = self.decoder(z)\n",
    "        \n",
    "        return x_hat, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, x_hat, mean, logvar, kl_weight=0.5):\n",
    "    \n",
    "    # mse = nn.MSELoss(reduction='mean')\n",
    "    # reconstruction_loss = mse(x, x_hat)\n",
    "    reconstruction_loss = torch.mean(torch.sum( (x-x_hat)**2, axis=1 ))\n",
    "    kl_loss = - 0.5 * torch.sum( 1 + logvar - mean**2 - logvar.exp())\n",
    "    \n",
    "    # return reconstruction_loss + kl_loss, kl_loss, reconstruction_loss\n",
    "    \n",
    "    return (1-kl_weight)*(reconstruction_loss) + kl_weight*kl_loss, kl_loss, reconstruction_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.to(device)\n",
    "\n",
    "def train_VAE(\n",
    "    X_data = X_data,\n",
    "    n_epochs = 10,\n",
    "    optimizer = None,\n",
    "    model = None,\n",
    "    kl_weight = 0.5\n",
    "):\n",
    "    \n",
    "    print(f\"Start training {n_epochs} epochs\")\n",
    "    rec_losses = []\n",
    "    kl_losses = []\n",
    "    losses = []\n",
    "    \n",
    "    # model.train()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # forward pass\n",
    "        x_hat, mean, logvar = model(X_data)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        # print(x_hat)\n",
    "        loss, kl_loss, rec_loss = vae_loss(X_data, x_hat, mean, logvar, kl_weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # reporting out\n",
    "        losses.append(loss.item())\n",
    "        kl_losses.append(kl_loss.item())\n",
    "        rec_losses.append(rec_loss.item())\n",
    "        print(f\"Epoch {epoch+1} / {n_epochs} -- loss = {loss.item():.4f} -- rec_loss = {rec_loss.item():.4f} -- kl_loss = {kl_loss.item():.4f}\") #, end=\"\\r\")\n",
    "        \n",
    "    return losses, rec_losses, kl_losses  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking basic AutoEncoding - we set scale at 0, so the model beahaves as a simple AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 8\n",
    "\n",
    "vae = ToyVAE(latent_dim=LATENT_DIM).to(device)\n",
    "lr = 1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, rec_losses, kl_losses = train_VAE(X_data, optimizer=optimizer, model=vae, n_epochs=100, kl_weight=1e-6)\n",
    "plt.plot(losses, label='losses')\n",
    "plt.plot(rec_losses, label='rec_losses')\n",
    "plt.plot(kl_losses, label='kl_losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_hat_data, mu, log_var = vae(X_data)\n",
    "    \n",
    "display(X_data.cpu(), X_hat_data.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.a\n",
    "\n",
    "- GANs are difficult to train by definition of their loss function, composed of KL divergences. See above.\n",
    "- WGANs bring some improvement, but the Lipschitz constraint on the discriminator is difficult to enforce. When using weigh_clipping, the clip value is hard to tune. When using gradient penalty, the weight on the gradient penalty is hard to turn.\n",
    "- VAE proved surprinsigly difficult to tune, even on the two-moons toy case. If the weight on the KL-loss is too strong, then the algorithm will collapse the outputs to 0, as this actually minimizes the KL-divergence of the latent variable. This is probably due to the fact that the original data lies in $\\mathbb{R}^2$, and it makes little sense to encode into a higher dimension latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.b\n",
    "\n",
    "- It is clear from the drawings that the generators of the GANs and WGANs are not doing a good job at covering the data distribution. This was clear as the training of the models was not satisfactory.\n",
    "- In the case of the VAE, the plot shows a much better coverage. However, this is not truly satisfactory, as we are using a latent space of higher dimension that the data space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128 # can go to 4096+ for RTX 3080\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "datapath = '/home/benjamin.deporte/MVA/TP_GenAI_MVA_2025_02_25/data'  # setup IRT\n",
    "# datapath = '/home/benjamin/Folders_Python/TP_GenAI_MVA_2025_02_25/data'  # setup CPU local\n",
    "train_set = MNIST(datapath, train=True, transform=transform, download=True)\n",
    "train_loader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying function\n",
    "def imshow(img,size=None):\n",
    "    img = img*0.5 + 0.5     # unnormalize\n",
    "    if size is not None:\n",
    "      img = transforms.Resize(size=size, interpolation=transforms.InterpolationMode.NEAREST, antialias=True)(img)\n",
    "    pil_img = torchvision.transforms.functional.to_pil_image(img)\n",
    "    plt.imshow(pil_img)\n",
    "    # print(\"Image size (h x w): \",  pil_img.height, \"x\", pil_img.width)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real,_ = next(iter(train_loader))\n",
    "print(real.shape)\n",
    "\n",
    "pil_img = imshow(torchvision.utils.make_grid(real.to('cpu'),nrow=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size  of generator input\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator and discriminator\n",
    "ngf, ndf = 64, 64\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels = nz, out_channels = ngf * 8, kernel_size = 4, stride = 1, padding = 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(in_channels = ngf * 8, out_channels = ngf * 4, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(in_channels = ngf * 4, out_channels = ngf * 2, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(in_channels = ngf * 2, out_channels = ngf, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(in_channels = ngf, out_channels = 1, kernel_size=1, stride=1, padding=2, bias=False),\n",
    "            nn.Tanh()\n",
    "            # output size. 1 x 28 x 28\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is 1 x 28 x 28\n",
    "            nn.Conv2d(in_channels = 1, out_channels = ndf, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 15 x 15\n",
    "            nn.Conv2d(in_channels = ndf, out_channels= ndf * 2, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 8 x 8\n",
    "            nn.Conv2d(in_channels = ndf * 2, out_channels = ndf * 4, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 5 x 5\n",
    "            nn.Conv2d(in_channels = ndf * 4, out_channels = 1, kernel_size = 4, stride = 2, padding = 1, bias=False)\n",
    "        )\n",
    "        self.prob = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.prob(self.main(input).view(-1, 1).squeeze(1))\n",
    "\n",
    "# Create some generator and discriminator\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display samples of the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display samples of the generator\n",
    "def show(G,z=None,batch_size=128,nz=100):\n",
    "  # provide random latent code as option to see evolution\n",
    "  with torch.no_grad():\n",
    "    if z==None:\n",
    "      z = torch.randn(batch_size,nz,1,1).to(device)\n",
    "      # print(f\"z = {z.size()}\")\n",
    "    genimages = G(z)\n",
    "    pil_img = imshow(torchvision.utils.make_grid(genimages.to('cpu'),nrow=16))\n",
    "    return(pil_img)\n",
    "\n",
    "# Load a pre-learned generator to see what you will get at the end of the practical session!:\n",
    "G = Generator().to(device)\n",
    "# G.load_state_dict(torch.hub.load_state_dict_from_url('https://perso.telecom-paristech.fr/aleclaire/mva/tp/wgan_epoch100.pt', progress=False))\n",
    "\n",
    "# Display samples\n",
    "show(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weigths Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Create the generator and discriminator\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.02.\n",
    "G.apply(weights_init);\n",
    "D.apply(weights_init);\n",
    "\n",
    "show(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Training loop - WGAN with Gradient Penalty for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small dataloader to test the pipeline\n",
    "\n",
    "# N_SMALL = 500\n",
    "# subset_indices = range(N_SMALL)\n",
    "# subset = Subset(train_set, subset_indices)\n",
    "\n",
    "# sample_loader = data.DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_gradient_norm(n_samples=10):\n",
    "    # Estimate Gradient of Discriminator on n_samples points\n",
    "            \n",
    "    # Sample points from the generator\n",
    "    z = torch.randn(n_samples,nz,1,1).to(device)\n",
    "    x_fake_sampled = G(z) # shape : N x 1 x 28 x 28\n",
    "    # print(f\"x_real = {x_real.size()}\")\n",
    "    # print(f\"x_fake_sampled = {x_fake_sampled.size()}\")\n",
    "            \n",
    "    # # Calculate interpolation between data and generated points\n",
    "    alpha = torch.rand((n_samples,1,1,1),device=device) # N x 1 x 1 x 1\n",
    "    # print(f\"alpha = {alpha.size()}\")\n",
    "    # print(f\"exemple alpha = {alpha[0]}\")\n",
    "    interp = (alpha * x_fake_sampled + (1-alpha) * x_real[:n_samples,:,:,:]) # N x 1 x 28 x 28\n",
    "    # print(f\"interp = {interp.size()}\")\n",
    "    interp.requires_grad_()\n",
    "            \n",
    "    D_interp = D(interp) # N x 1\n",
    "    # print(f\"D_interp = {D_interp.size()}\")\n",
    "    gradout = torch.ones(D_interp.size()).to(device) # N x 1\n",
    "    # print(f\"gradouts = {gradout.size()}\") # N x 1\n",
    "    # autograd will actually compute a Gradient tensor N x 1 x 28 x 28, \n",
    "    # as output is D_interp shape B\n",
    "    # and input is interp shape N x 1 x 28 x 28\n",
    "    # ----\n",
    "    # gradients is shape N x 1 x 28 x 28\n",
    "    gradients = torch.autograd.grad(outputs = D_interp, inputs = interp, grad_outputs = gradout, create_graph = True, retain_graph = True)[0] # N x 1 x 28 x 28\n",
    "    # print(f\"gradients = {gradients.size()}\")\n",
    "    # -----\n",
    "    # compute gradient norm estimate\n",
    "    norms_squared = torch.sqrt(torch.sum(gradients**2,(2,3))) # B x 1 \n",
    "    # print(f\"norms_squared = {norms_squared.size()}\")\n",
    "    est_gradient_norm = torch.mean(norms_squared) #  1\n",
    "    # print(est_gradient_norm)\n",
    "    \n",
    "    return est_gradient_norm\n",
    "\n",
    "# est_gradient_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # initialize random seed for reproducibility\n",
    "\n",
    "num_epochs = 2\n",
    "log_every = 100\n",
    "gpw = 5\n",
    "\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "G.apply(weights_init);\n",
    "D.apply(weights_init);\n",
    "optimD = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimG = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "niterD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "list_gradient_norms = []\n",
    "Dlosses = []\n",
    "Dlosses_wogp = []\n",
    "Glosses = []\n",
    "Gradient_norms = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the train_loader\n",
    "    losses_d_batch = []\n",
    "    losses_d_wogp_batch = []\n",
    "    losses_g_batch = []\n",
    "    gradient_norms_batch = []\n",
    "    \n",
    "    for i, batch in enumerate(train_loader, 0):\n",
    "         \n",
    "        # losses_batch = []\n",
    "        # gradient_norm_batch = []\n",
    "\n",
    "        ############################\n",
    "        # Draw Batches \n",
    "        ############################\n",
    "        \n",
    "        x_real = batch[0].to(device)  # B x 1 x 28 x 28\n",
    "        # print(f\"x_real = {x_real.size()}\")\n",
    "        \n",
    "        x_fake = G(torch.randn(batch_size,nz,1,1).to(device)) # B x 1 x 28 x 28\n",
    "        # print(f\"x_fake = {x_fake.size()}\")\n",
    "        \n",
    "        ################################\n",
    "        # Train Discriminator \n",
    "        ################################\n",
    "        \n",
    "        for j in range(niterD):\n",
    "            # print(f\"Discriminator training {j+1} / {niterD}\", end=\"\\r\")\n",
    "            \n",
    "            optimD.zero_grad()\n",
    "            # Dloss sans gradient penalty : best is -1, worst is 1\n",
    "            # loss sans la régul gradient penalty\n",
    "            Dloss_wogp = - (torch.mean(D(x_real)) - torch.mean(D(x_fake)))\n",
    "            \n",
    "            gradient_norm = est_gradient_norm()\n",
    "            \n",
    "            # calculate the loss with gradient penalty\n",
    "            Dloss = Dloss_wogp + gpw * (gradient_norm - 1)**2\n",
    "                        \n",
    "            # optimize\n",
    "            optimD.zero_grad()\n",
    "            Dloss.backward(retain_graph=True)\n",
    "            optimD.step()\n",
    "          \n",
    "        # iteration losses log\n",
    "        losses_d_wogp_batch.append(Dloss_wogp.item())\n",
    "        losses_d_batch.append(Dloss.item())\n",
    "        gradient_norms_batch.append(gradient_norm.item())\n",
    "    \n",
    "        ############################\n",
    "        # Update G network\n",
    "        ############################\n",
    "        \n",
    "        # Gloss : best is -1, worst is 0\n",
    "        Gloss = - torch.mean(D(G(torch.randn(batch_size,nz,1,1).to(device))))\n",
    "        optimG.zero_grad()\n",
    "        Gloss.backward()\n",
    "        optimG.step()\n",
    "        \n",
    "        losses_g_batch.append(Gloss.item())\n",
    "        \n",
    "        # reporting\n",
    "        print(f\"batch {i+1} / {len(train_loader)} \\\n",
    "            -- avg D loss sans GP = {np.average(losses_d_wogp_batch):.4f} \\\n",
    "            -- avg G loss = {np.average(losses_g_batch):.4f} \\\n",
    "            -- Gradient norm estimate : {gradient_norm:.4f}\", \\\n",
    "            end=\"\\r\")\n",
    "        \n",
    "        ##############################\n",
    "        ## Log \n",
    "        ##############################\n",
    "        \n",
    "    loss_d_wogp_epoch = np.average(losses_d_wogp_batch)\n",
    "    loss_d_epoch = np.average(losses_d_batch)\n",
    "    loss_g_epoch = np.average(losses_g_batch)\n",
    "    gradient_norm_epoch = np.average(gradient_norms_batch)\n",
    "    \n",
    "    Dlosses_wogp.append(loss_d_wogp_epoch)\n",
    "    Dlosses.append(loss_d_epoch)\n",
    "    Glosses.append(loss_g_epoch)\n",
    "    Gradient_norms.append(gradient_norm_epoch)\n",
    "       \n",
    "    print(f\"epoch : {epoch+1} / {num_epochs} \\\n",
    "        --- loss D sans GP = {loss_d_wogp_epoch:.4f} \\\n",
    "        --- loss G = {loss_g_epoch:.4f} \\\n",
    "        --- gradient norm = {gradient_norm_epoch:.4f} \\\n",
    "                                                                \")\n",
    "    \n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(batch_size,nz,1,1).to(device)\n",
    "    genimages = G(z)\n",
    "    pil_img = imshow(torchvision.utils.make_grid(genimages.to('cpu'),nrow=16))\n",
    "\n",
    "tlt = time.time()-t0\n",
    "print(f'Total learning time = {tlt:.4f}')\n",
    "\n",
    "# # Save final generator in a variable for later use\n",
    "# wgan = Generator()\n",
    "# wgan.load_state_dict(G.state_dict())\n",
    "\n",
    "# # Save final generator in a file\n",
    "# torch.save(G.state_dict(), 'wgan.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Dlosses_wogp, label=\"D loss sans GP\")\n",
    "plt.plot(Glosses, label='G loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "hidden_dim = 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder2D(nn.Module):\n",
    "        def __init__(self, latent_dim=latent_dim):\n",
    "                super(Encoder2D, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "                self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "                self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=7, padding=3)\n",
    "                n = hidden_dim # 32 x 3 x 3\n",
    "                self.fc_mu = nn.Linear(n, latent_dim)\n",
    "                self.fc_logvar = nn.Linear(n, latent_dim)\n",
    "                \n",
    "        def forward(self,inputs):\n",
    "                # input is B x 1 x 28 x 28\n",
    "                x = self.conv1(inputs) # out : B x 16 x 28 x 28\n",
    "                x = F.relu(nn.AvgPool2d(2)(x)) # out : B x 16 x 14 x 14\n",
    "                x = self.conv2(x) # out : batch x 32 x 14 x 14\n",
    "                x = F.relu(nn.AvgPool2d(2)(x)) # out : B x 32 x 7 x 7\n",
    "                x = self.conv3(x) # out : B x 32 x 7 x 7\n",
    "                x = F.relu(nn.AvgPool2d(2)(x)) # out : B x 32 x 3 x 3\n",
    "                x = x.view((x.size()[0], -1)) # out : B x 288\n",
    "                mu_x = self.fc_mu(x) # out : B x latent_dim\n",
    "                logvar_x = self.fc_logvar(x) # out : B x latent_dim\n",
    "                return mu_x, logvar_x\n",
    "        \n",
    "# encoder = Encoder2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderMLP(nn.Module):\n",
    "        def __init__(self, latent_dim=latent_dim, n_neurons=32):\n",
    "                super(EncoderMLP, self).__init__()\n",
    "                self.fc1 = nn.Linear(1*28*28, n_neurons)\n",
    "                self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "                self.fc3 = nn.Linear(n_neurons, n_neurons)\n",
    "                self.fc_mu = nn.Linear(n_neurons, latent_dim)\n",
    "                self.fc_logvar = nn.Linear(n_neurons, latent_dim)\n",
    "                \n",
    "        def forward(self,inputs):\n",
    "                # input is B x 1 x 28 x 28\n",
    "                x = inputs.view(inputs.size()[0],-1)                # x = self.deconv1(x) # out : B x 32 x 3 x 3\n",
    "                # x = self.deconv2(x) # out : B x 32 x 6 x 6\n",
    "                # x = self.deconv3(x) # out : B x 32 x 12 x 12\n",
    "                # x = self.deconv4(x) # out : B x 32 x 28 x 28\n",
    "                x = F.relu(self.fc1(x)) # out : B x 16 x 14 x 14\n",
    "                x = F.relu(self.fc2(x)) # out : B x 32 x 7 x 7\n",
    "                x = F.relu(self.fc3(x)) \n",
    "                mu_x = self.fc_mu(x) # out : B x latent_dim\n",
    "                logvar_x = self.fc_logvar(x) # out : B x latent_dim\n",
    "\n",
    "                return mu_x, logvar_x\n",
    "        \n",
    "encoder = EncoderMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking dimensions...\n",
    "# \n",
    "batch_example_size = 8\n",
    "\n",
    "x = torch.randn((batch_example_size,1,28,28))\n",
    "print(f\"input = {x.shape}\")\n",
    "\n",
    "mu, logvar = encoder(x)\n",
    "print(f\"output mu = {mu.shape}\")\n",
    "print(f\"output logvar = {logvar.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decoder to sample back from vector latent_dim to 28 x 28\n",
    "\n",
    "class Decoder2D(nn.Module):\n",
    "        def __init__(self, latent_dim=latent_dim):\n",
    "                super(Decoder2D, self).__init__()\n",
    "                n_hidden = hidden_dim\n",
    "                # print(f\"entrée de rsample : mu = {mu.size()}\")\n",
    "                # print(f\"entrée de rsample : std = {std.size()}\")    \n",
    "                self.fc1 = nn.Linear(latent_dim, n_hidden)\n",
    "                self.deconv1 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "                self.deconv2 = nn.ConvTranspose2d(32, 32, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "                self.deconv3 = nn.ConvTranspose2d(32, 32, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "                self.deconv4 = nn.ConvTranspose2d(32, 1, kernel_size=7, stride=2, padding=1, output_padding=1)\n",
    "                \n",
    "        def forward(self, inputs):\n",
    "                B = inputs.size(0)  # number of batches\n",
    "                x = inputs # out = B x latent_dim\n",
    "                x = F.relu(self.fc1(x)) # out : B x (hidden_dim)\n",
    "                x = x.reshape(x.shape[0], 32, 3, 3) # out B * 32 * 3 * 3\n",
    "                x = self.deconv1(x) # out : B x 32 x 3 x 3\n",
    "                x = self.deconv2(x) # out : B x 32 x 6 x 6\n",
    "                x = self.deconv3(x) # out : B x 32 x 12 x 12\n",
    "                x = self.deconv4(x) # out : B x 32 x 28 x 28\n",
    "                \n",
    "                return x\n",
    "        \n",
    "# # decoder = Decoder2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder to sample back from vector latent_dim to 28 x 28\n",
    "\n",
    "class DecoderMLP(nn.Module):\n",
    "        def __init__(self, latent_dim=latent_dim, n_neurons=32):\n",
    "                super(DecoderMLP, self).__init__()\n",
    "\n",
    "                self.fc1 = nn.Linear(latent_dim, n_neurons)\n",
    "                self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "                self.fc3 = nn.Linear(n_neurons, 1*28*28)\n",
    "                \n",
    "        def forward(self, inputs):\n",
    "                x = F.relu(self.fc1(inputs))\n",
    "                x = F.relu(self.fc2(x))\n",
    "                x = self.fc3(x)\n",
    "                x = x.view(x.size()[0],1,28,28)\n",
    "                x = F.tanh(x)\n",
    "                \n",
    "                return x\n",
    "        \n",
    "decoder = DecoderMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "\n",
    "x = torch.randn(8, latent_dim) # B (batch size) x latent_dim\n",
    "print(f\"input shape = {x.shape}\")\n",
    "out = decoder(x)\n",
    "print(f\"output shape = {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistVAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_neurons=16, latent_dim=2): #, scale=1.0):\n",
    "        super(MnistVAE, self).__init__()\n",
    "        \n",
    "        self.encoder = EncoderMLP(latent_dim=latent_dim)\n",
    "        self.decoder = DecoderMLP(latent_dim=latent_dim)\n",
    "        # self.scale = scale\n",
    "        \n",
    "    def rsample(self, mean, std): #, scale=None):\n",
    "        # mean : B x latent_dim\n",
    "        # std : B x latent_dim\n",
    "        # if scale is None:\n",
    "        #     scale=self.scale\n",
    "        epsilon = torch.randn_like(mean) # N(0,1) shape B x latent_dim \n",
    "        z = mean + std * epsilon # * scale # B x 1 \\sim \\mathcal{N}(mu, var)\n",
    "        return z\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        std = torch.exp(0.5 * logvar) # we scale by sqrt(diag(var))\n",
    "        # print(f\"entrée de rsample : mu = {mu.size()}\")\n",
    "        # print(f\"entrée de rsample : std = {std.size()}\")\n",
    "        z = self.rsample(mu, std)\n",
    "        # print(f\"z samplé = {z.size()}\")\n",
    "        x_hat = self.decoder(z)\n",
    "        \n",
    "        return x_hat, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "mvae = MnistVAE(latent_dim=latent_dim)\n",
    "\n",
    "x = torch.randn(128, 1, 28, 28) # B (batch size) x 1 x 28 x 28\n",
    "\n",
    "print(f\"input shape = {x.shape}\")\n",
    "\n",
    "x_hat, mu, logvar = mvae(x)\n",
    "\n",
    "print(f\"outputs shapes : x_hat = {x_hat.size()}, mus = {mu.size()},  logvars = {logvar.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_vae_loss(x, x_hat, mean, logvar, kl_weight=0.5):\n",
    "    \n",
    "    reconstruction_loss = torch.mean(torch.sum( (x-x_hat)**2, axis=[1,2,3] ))\n",
    "    kl_loss = - 0.5 * torch.sum( 1 + logvar - mean**2 - logvar.exp()) # validé\n",
    "    \n",
    "    # print(f\"reconstruction loss = {reconstruction_loss}\")\n",
    "    # print(f\"KL loss = {kl_loss}\")\n",
    "    \n",
    "    return (1-kl_weight)*(reconstruction_loss) + kl_weight*kl_loss, kl_loss, reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = mnist_vae_loss(x, x_hat, mu, logvar)\n",
    "print(f\"Total loss = {l}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST VAE Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MNIST_VAE(\n",
    "    loader = None,\n",
    "    n_epochs = 10,\n",
    "    optimizer = None,\n",
    "    model = None,\n",
    "    kl_weight = 0.5\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        loader (_type_, optional): sample_loader ou train_loader. Defaults to None.\n",
    "        n_epochs (int, optional): _description_. Defaults to 10.\n",
    "        optimizer (_type_, optional): _# Decoder to sample back from vector latent_dim to 28 x 28\n",
    "\n",
    "class Decoder2D(nn.Module):\n",
    "        def __init__(self, latent_dim=latent_dim):\n",
    "                super(Decoder2D, self).__init__()\n",
    "                n_hidden = hidden_dim\n",
    "                # print(f\"entrée de rsample : mu = {mu.size()}\")\n",
    "                # print(f\"entrée de rsample : std = {std.size()}\")    self.fc1 = nn.Linear(latent_dim, n_hidden)\n",
    "                self.deconv1 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "                self.deconv2 = nn.ConvTranspose2d(32, 32, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "                self.deconv3 = nn.ConvTranspose2d(32, 32, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "                self.deconv4 = nn.ConvTranspose2d(32, 1, kernel_size=7, stride=2, padding=1, output_padding=1)\n",
    "                \n",
    "        def forward(self, inputs):\n",
    "                B = inputs.size(0)  # number of batches\n",
    "                x = inputs # out = B x latent_dim\n",
    "                x = F.relu(self.fc1(x)) # out : B x (hidden_dim)\n",
    "                x = x.reshape(x.shape[0], 32, 3, 3) # out B * 32 * 3 * 3\n",
    "                x = self.deconv1(x) # out : B x 32 x 3 x 3\n",
    "                x = self.deconv2(x) # out : B x 32 x 6 x 6\n",
    "                x = self.deconv3(x) # out : B x 32 x 12 x 12\n",
    "                x = self.deconv4(x) # out : B x 32 x 28 x 28\n",
    "                \n",
    "                return x\n",
    "        \n",
    "decoder = Decoder2D()description_. Defaults to None.\n",
    "        model (_type_, optional): _description_. Defaults to None.\n",
    "        kl_weight (float, optional): _description_. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        _type_: lists of losses\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Start training {n_epochs} epochs on MNIST VAE\")\n",
    "    rec_losses = []\n",
    "    kl_losses = []\n",
    "    total_losses = []\n",
    "    \n",
    "    # model.train()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # init batch measurements\n",
    "        batch_kl_losses = []\n",
    "        batch_rec_losses = []\n",
    "        batch_total_losses = []\n",
    "        \n",
    "        for i, batch in enumerate(loader, 0):\n",
    "            \n",
    "            # forward pass\n",
    "            x = batch[0]\n",
    "            x_hat, mean, logvar = model(x)\n",
    "            \n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            # print(x_hat)\n",
    "            total_loss, kl_loss, rec_loss = mnist_vae_loss(x, x_hat, mean, logvar, kl_weight)\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # logging at batch level\n",
    "            batch_kl_losses.append(kl_loss.item())\n",
    "            batch_rec_losses.append(rec_loss.item())\n",
    "            batch_total_losses.append(total_loss.item())\n",
    "            \n",
    "            # reporting out at batch level\n",
    "            print(f\"Batch {i+1} / {len(loader)} \\\n",
    "            -- total loss = {batch_total_losses[-1]:.4f} \\\n",
    "            -- reco loss = {batch_rec_losses[-1]:.4f} \\\n",
    "            -- KL loss = {batch_kl_losses[-1]:.4f}\", \\\n",
    "            end=\"\\r\")\n",
    "            \n",
    "        # logging at epoch level\n",
    "        total_losses.append(np.average(batch_total_losses))  \n",
    "        rec_losses.append(np.average(batch_rec_losses)) \n",
    "        kl_losses.append(np.average(batch_kl_losses)) \n",
    "        \n",
    "        # reporting out at epoch level\n",
    "        print(f\"Epoch {epoch+1} / {n_epochs} \\\n",
    "            -- loss = {total_losses[-1]:.4f} \\\n",
    "            -- rec_loss = {rec_losses[-1]:.4f} \\\n",
    "            -- kl_loss = {kl_losses[-1]:.4f} \\\n",
    "                                           \"\n",
    "        ) #, end=\"\\r\")\n",
    "        \n",
    "    return total_losses, rec_losses, kl_losses  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small dataloader to test the pipeline\n",
    "\n",
    "# N_SMALL = 1000\n",
    "# subset_indices = range(N_SMALL)\n",
    "# subset = Subset(train_set, subset_indices)\n",
    "\n",
    "# sample_loader = data.DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "mnist_vae = MnistVAE(latent_dim=latent_dim)\n",
    "\n",
    "lr = 1e-2\n",
    "optimizer = torch.optim.Adam(mnist_vae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "kl_weight = 0.5\n",
    "\n",
    "total_losses, rec_losses, kl_losses = train_MNIST_VAE(\n",
    "    loader=train_loader, \n",
    "    n_epochs=n_epochs, \n",
    "    optimizer=optimizer, \n",
    "    model=mnist_vae,\n",
    "    kl_weight=kl_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12,6), nrows=1, ncols=2)\n",
    "\n",
    "axs[0].set_title(f\"Rec Loss v Epochs\")\n",
    "axs[0].plot(rec_losses, label=\"Rec loss\")\n",
    "axs[0].legend()\n",
    "axs[0].grid()\n",
    "\n",
    "axs[1].set_title(f\"KL Loss v Epochs\")\n",
    "axs[1].plot(kl_losses, label=\"KL loss\")\n",
    "axs[1].legend()\n",
    "axs[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get original images\n",
    "\n",
    "N_SAMPLES = 16\n",
    "\n",
    "real, label = next(iter(train_loader))\n",
    "\n",
    "real = real[:N_SAMPLES]\n",
    "pil_img = imshow(torchvision.utils.make_grid(real.to(device),nrow=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus, logvars = mnist_vae.encoder(real)\n",
    "samples = mnist_vae.decoder(mus)\n",
    "\n",
    "pil_samples_img = imshow(torchvision.utils.make_grid(samples.to(device),nrow=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing pipeline to use Binary Cross Entropy as a loss instead of L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we normalize between 0 and 1\n",
    "batch_size=128 # can go to 4096+ for RTX 3080\n",
    "\n",
    "# file path, depends where we run\n",
    "datapath = '/home/benjamin.deporte/MVA/TP_GenAI_MVA_2025_02_25/data'  # setup IRT\n",
    "# datapath = '/home/benjamin/Folders_Python/TP_GenAI_MVA_2025_02_25/data'  # setup CPU local\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset2 = MNIST(datapath, train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset2 = MNIST(datapath, train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader for FULL dataset \n",
    "train_loader2 = torch.utils.data.DataLoader(dataset=train_dataset2, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader2 = torch.utils.data.DataLoader(dataset=test_dataset2, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
    "\n",
    "# Small dataloader to test the pipeline\n",
    "N_SMALL = 1000\n",
    "subset_indices = range(N_SMALL)\n",
    "subset = Subset(train_dataset2, subset_indices)\n",
    "\n",
    "sample_loader = data.DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real,_ = next(iter(train_loader2))\n",
    "print(real.shape)\n",
    "\n",
    "pil_img = imshow(torchvision.utils.make_grid(real.to('cpu'),nrow=16))\n",
    "\n",
    "print(f\"Min = {real[0].min()}\")\n",
    "print(f\"Max = {real[0].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting simple : encoder and decoder are MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderMLP2(nn.Module):\n",
    "        def __init__(self, latent_dim=latent_dim, n_neurons=512):\n",
    "                super(EncoderMLP2, self).__init__()\n",
    "                \n",
    "                self.fc1 = nn.Linear(1*28*28, n_neurons)\n",
    "                self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "                # self.fc3 = nn.Linear(n_neurons, n_neurons)\n",
    "                self.fc_mu = nn.Linear(n_neurons, latent_dim)\n",
    "                self.fc_logvar = nn.Linear(n_neurons, latent_dim)\n",
    "                                \n",
    "        def forward(self,inputs):\n",
    "                # input is B x 1 x 28 x 28\n",
    "                x = inputs.view(-1, 784)             \n",
    "                x = F.relu(self.fc1(x)) \n",
    "                x = F.relu(self.fc2(x)) \n",
    "                mu_x = self.fc_mu(x) # out : B x latent_dim\n",
    "                logvar_x = self.fc_logvar(x) # out : B x latent_dim\n",
    "\n",
    "                return mu_x, logvar_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking dimensions...\n",
    "# # \n",
    "# encoder = EncoderMLP2()\n",
    "\n",
    "# batch_example_size = 8\n",
    "\n",
    "# x = torch.randn((batch_example_size,1,28,28))\n",
    "# print(f\"input = {x.shape}\")\n",
    "\n",
    "# mu, logvar = encoder(x.view(-1,784))\n",
    "# print(f\"output mu = {mu.shape}\")\n",
    "# print(f\"output logvar = {logvar.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder to sample back from vector latent_dim to 28 x 28 within [0,1]^784\n",
    "\n",
    "class DecoderMLP2(nn.Module):\n",
    "        def __init__(self, latent_dim=latent_dim, n_neurons=256):\n",
    "                super(DecoderMLP2, self).__init__()\n",
    "\n",
    "                # self.fc1 = nn.Linear(latent_dim, n_neurons)\n",
    "                # self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "                # self.fc3 = nn.Linear(n_neurons, 1*28*28)\n",
    "                \n",
    "                self.fc4 = nn.Linear(latent_dim, 256)\n",
    "                self.fc5 = nn.Linear(256, 512)\n",
    "                self.fc6 = nn.Linear(512, 784)\n",
    "                \n",
    "        def forward(self, inputs):\n",
    "                x = F.relu(self.fc4(inputs))\n",
    "                x = F.relu(self.fc5(x))\n",
    "                x = F.sigmoid(self.fc6(x))\n",
    "                \n",
    "                return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check dimensions\n",
    "# decoder = DecoderMLP2()\n",
    "# x = torch.randn(8, latent_dim) # B (batch size) x latent_dim\n",
    "# print(f\"input shape = {x.shape}\")\n",
    "# out = decoder(x)\n",
    "# print(f\"output shape = {out.shape}\")\n",
    "\n",
    "# print(out.min())\n",
    "# print(out.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistVAE2(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_neurons=256, latent_dim=2): #, scale=1.0):\n",
    "        super(MnistVAE2, self).__init__()\n",
    "        \n",
    "        self.encoder = EncoderMLP2(latent_dim=latent_dim)\n",
    "        self.decoder = DecoderMLP2(latent_dim=latent_dim)\n",
    "        \n",
    "    def rsample(self, mean, std):\n",
    "        # mean : B x latent_dim\n",
    "        # std : B x latent_dim\n",
    "        epsilon = torch.randn_like(mean) # N(0,1) shape B x latent_dim \n",
    "        z = mean + std * epsilon # * scale # B x 1 \\sim \\mathcal{N}(mu, var)\n",
    "        return z\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        # encoder forward\n",
    "        mu_x, logvar_x = self.encoder(x)\n",
    "        \n",
    "        # sample with reparametrisation trick\n",
    "        std_x = torch.exp(0.5 * logvar_x)\n",
    "        z = self.rsample(mu_x, std_x)\n",
    "        \n",
    "        # decoder forward\n",
    "        x_hat = self.decoder(z)\n",
    "        \n",
    "        return x_hat, mu_x, logvar_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check dimensions\n",
    "# mvae = MnistVAE2(latent_dim=latent_dim)\n",
    "\n",
    "# x = torch.randn(128, 1, 28, 28) # B (batch size) x 1 x 28 x 28\n",
    "\n",
    "# print(f\"input shape = {x.shape}\")\n",
    "\n",
    "# x_hat, mu, logvar = mvae(x)\n",
    "\n",
    "# print(f\"outputs shapes : x_hat = {x_hat.size()}, mus = {mu.size()},  logvars = {logvar.size()}\")\n",
    "\n",
    "# print(x_hat.min())\n",
    "# print(x_hat.max())\n",
    "\n",
    "# must be :\n",
    "# input shape = torch.Size([128, 1, 28, 28])\n",
    "# outputs shapes : x_hat = torch.Size([128, 784]), mus = torch.Size([128, 2]),  logvars = torch.Size([128, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_vae_bceloss(x, x_hat, mean, logvar): #, kl_weight=0.5):\n",
    "    \n",
    "    reconstruction_loss = F.binary_cross_entropy(x, x_hat, reduction='mean')\n",
    "    kl_loss = - 0.5 * torch.sum( 1 + logvar - mean**2 - logvar.exp())\n",
    "\n",
    "    return reconstruction_loss + kl_loss, kl_loss, reconstruction_loss # + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = next(iter(train_loader2))[0]\n",
    "\n",
    "# x_hat, mu, logvar = mvae(x.view(-1,784))\n",
    "# print(x.size())\n",
    "# print(x_hat.size())\n",
    "# print(x_hat.min())\n",
    "# print(x_hat.max())\n",
    "# mnist_vae_bceloss(x, x_hat, mu, logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MNIST_VAE_BCE(\n",
    "    loader = None,\n",
    "    n_epochs = 50,\n",
    "    optimizer = None,\n",
    "    model = None,\n",
    "    kl_weight = 0.5\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        loader (_type_, optional): sample_loader ou train_loader. Defaults to None.\n",
    "        n_epochs (int, optional): _description_. Defaults to 50.\n",
    "        optimizer (_type_, optional): \n",
    "        kl_weight : weight of the KL in the total loss, should not be changed. Default to 0.5\n",
    "        \n",
    "    Returns:\n",
    "        _type_: lists of losses\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Start training {n_epochs} epochs on MNIST VAE\")\n",
    "    rec_losses = []\n",
    "    kl_losses = []\n",
    "    total_losses = []\n",
    "       \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # init batch measurements\n",
    "        batch_kl_losses = []\n",
    "        batch_rec_losses = []\n",
    "        batch_total_losses = []\n",
    "        \n",
    "        for i, batch in enumerate(loader, 0):\n",
    "            \n",
    "            # forward pass\n",
    "            x = batch[0].view(-1,784)\n",
    "            x_hat, mean, logvar = model(x)\n",
    "            \n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            total_loss, kl_loss, rec_loss = mnist_vae_bceloss(x_hat, x, mean, logvar) # Nasty bug : x_hat and x not interchangeable...\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # logging at batch level\n",
    "            batch_kl_losses.append(kl_loss.item())\n",
    "            batch_rec_losses.append(rec_loss.item())\n",
    "            batch_total_losses.append(total_loss.item())\n",
    "            \n",
    "            # reporting out at batch level\n",
    "            print(f\"Batch {i+1} / {len(loader)} \\\n",
    "            -- total loss = {batch_total_losses[-1]:.4f} \\\n",
    "            # -- reco loss = {batch_rec_losses[-1]:.4f} \\\n",
    "            # -- KL loss = {batch_kl_losses[-1]:.4f}\", \\\n",
    "            end=\"\\r\")\n",
    "            \n",
    "        # logging at epoch level\n",
    "        total_losses.append(np.average(batch_total_losses))  \n",
    "        rec_losses.append(np.average(batch_rec_losses)) \n",
    "        kl_losses.append(np.average(batch_kl_losses)) \n",
    "        \n",
    "        # reporting out at epoch level\n",
    "        print(f\"Epoch {epoch+1} / {n_epochs} \\\n",
    "            -- loss = {total_losses[-1]:.4f} \\\n",
    "            # -- rec_loss = {rec_losses[-1]:.4f} \\\n",
    "            # -- kl_loss = {kl_losses[-1]:.4f} \\\n",
    "                                           \")\n",
    "        \n",
    "    return total_losses, rec_losses, kl_losses  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "mvae = MnistVAE2(latent_dim=latent_dim)\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer_mvae = torch.optim.Adam(mvae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "total_losses, rec_losses, kl_losses = train_MNIST_VAE_BCE(\n",
    "    loader=sample_loader, \n",
    "    n_epochs=n_epochs, \n",
    "    optimizer=optimizer_mvae, \n",
    "    model=mvae,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(64, latent_dim)\n",
    "    sample = mvae.decoder(z)\n",
    "\n",
    "s = sample.view(64,1,28,28)\n",
    "\n",
    "pil_img = imshow(torchvision.utils.make_grid(s.to('cpu'),nrow=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next : encoder and decoder are Conv2D-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistVAE_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim=2): #, scale=1.0):\n",
    "        super(MnistVAE_CNN, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder2D(latent_dim=latent_dim)\n",
    "        self.decoder = Decoder2D(latent_dim=latent_dim)\n",
    "        \n",
    "    def rsample(self, mean, std):\n",
    "        # mean : B x latent_dim\n",
    "        # std : B x latent_dim\n",
    "        epsilon = torch.randn_like(mean) # N(0,1) shape B x latent_dim \n",
    "        z = mean + std * epsilon # * scale # B x 1 \\sim \\mathcal{N}(mu, var)\n",
    "        return z\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        # encoder forward\n",
    "        mu_x, logvar_x = self.encoder(x)\n",
    "        \n",
    "        # sample with reparametrisation trick\n",
    "        std_x = torch.exp(0.5 * logvar_x)\n",
    "        z = self.rsample(mu_x, std_x)\n",
    "        \n",
    "        # decoder forward\n",
    "        x_hat = F.sigmoid(self.decoder(z)).view(-1,784)\n",
    "        \n",
    "        return x_hat, mu_x, logvar_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check dimensions\n",
    "# mvae = MnistVAE_CNN(latent_dim=latent_dim)\n",
    "\n",
    "# x = torch.randn(128, 1, 28, 28) # B (batch size) x 1 x 28 x 28\n",
    "\n",
    "# print(f\"input shape = {x.shape}\")\n",
    "\n",
    "# x_hat, mu, logvar = mvae(x)\n",
    "\n",
    "# print(f\"outputs shapes : x_hat = {x_hat.size()}, mus = {mu.size()},  logvars = {logvar.size()}\")\n",
    "\n",
    "# print(x_hat.min())\n",
    "# print(x_hat.max())\n",
    "\n",
    "# MUST BE :\n",
    "# input shape = torch.Size([128, 1, 28, 28])\n",
    "# outputs shapes : x_hat = torch.Size([128, 784]), mus = torch.Size([128, 2]),  logvars = torch.Size([128, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "mvae = MnistVAE_CNN(latent_dim=latent_dim)\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer_mvae = torch.optim.Adam(mvae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "total_losses, rec_losses, kl_losses = train_MNIST_VAE_BCE(\n",
    "    loader=train_loader2, \n",
    "    n_epochs=n_epochs, \n",
    "    optimizer=optimizer_mvae, \n",
    "    model=mvae,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(64, latent_dim)\n",
    "    sample = mvae.decoder(z)\n",
    "\n",
    "s = sample.view(64,1,28,28)\n",
    "\n",
    "pil_img = imshow(torchvision.utils.make_grid(s.to('cpu'),nrow=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.a\n",
    "\n",
    "Not enough time to fine-tune the paramters and have the models actually generate images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.b\n",
    "\n",
    "Definitely VAE. It is actually easier to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frechet Inception Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
